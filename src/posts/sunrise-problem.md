---
title: Вокруг задачи о восходе солнца
date: 2022-07-13
---

Взойдёт ли завтра солнце? Странный вопрос, о котором вы вряд ли задумываетесь, ведь оно всходит каждый день. Да и чтобы ответить на этот вопрос,
потребуются обширные астрономические знания о Солнце. Давайте немного поменяем вопрос и посмотрим на него с точки зрения математики, а не
физики: какова вероятность того, что завтра взойдёт солнце? Вопрос всё ещё абсурден, однако на него можно постараться дать ответ.

Здравствуйте, дорогие любители математики и просто те, кого заинтересовала тема этой статьи! В настоящей статье я рассказываю об одной
замечательной задаче — задаче о восходе солнца. С этой задачей я познакомился на кружке по математическим основам информатики, который
ведут в лицее НИУ ВШЭ, и мне очень она понравилась.

Для комфортного чтения статьи желательно быть знакомым с основами теории вероятностей, такими как: условная и полная вероятности, теорема Байеса и
распределение вероятностей, а также уметь работать с интегралами.

### Немного об истории задачи

Задача о восходе солнца (англ. *sunrise problem*) была представлена в 1814 году великим математиком и физиком Пьером-Симоном
Лапласом в его работе *«Essai philosophique sur les probabilités»*. Формулировка задачи следующая: 

**«Какова вероятность того, что завтра взойдёт солнце?»**

Лаплас решил эту задачу с помощью своего
<a class="text-link" href="https://en.wikipedia.org/wiki/Rule_of_succession" target="_blank">правила последовательности</a> (англ. *rule of succession*), представленного в той же работе, которое гласит, что если провести эксперимент, оканчивающийся либо успехом, либо неудачей, $n$ раз независимо и получить в результате $s$ успехов и $n-s$ неудач, то вероятность того, что следующий эксперимент будет успешным, равна $(s+1) / (n+2)$.

Воспользуемся этим правилом для решения нашей задачи. Пусть солнце всходило $n=10000$ раз, тогда вероятность того, что оно взойдёт
завтра, равна $$\frac{n+1}{n+2} = \frac{10001}{10002} \approx 0.99990002$$ С каждым днём эта вероятность увеличивается, так как
увеличивается $n$. Однако Лаплас заметил, что такая вероятность восхода солнца всё равно кажется малой для нас, и на самом деле неправильно
в этой задаче применять правило последовательности. Действительно, представьте, что солнце не взойдёт завтра с вероятностью 
$1 - 0.99990002 = 0.00009998$. Мы не можем принять то, что есть такой большой шанс, что оно не взойдёт. Так думали и современники Лапласа,
поэтому в его адрес было много критики по поводу такого решения этой задачи. 

На самом деле, конечно, Лаплас не пытался по-настоящему оценить вероятность восхода солнца, это был лишь пример применения его
правила последовательности, однако пример не совсем удачный. Дело в том, что правило последовательности применяется для оценивания вероятности
в тех случаях, когда у нас нет почти никаких априорных знаний о системе, которую мы исследуем, однако в задаче о восходе солнца у нас есть 
априорные знания о том, как восходит солнце, поэтому и получаются описанные выше противоречия.

### Математическая постановка задачи

Давайте теперь сформулируем более полно, математически, правило последовательности. Пусть есть случайные величины 
$\xi_1, \xi_2,..., \xi_{n+1}$, такие, что $\xi_i \sim Bern(p)$ и все $\xi_i$ условно независимы относительно $p$, т.е.
$$P(\xi_i \cap \xi_j\\, |\\, p) = P(\xi_i\\, |\\, p)P(\xi_j\\, |\\, p)$$
Тогда, если больше нам ничего о них не известно, то $$P\biggl(\xi_{n+1} = 1\\, |\\, \sum_{i=1}^{n} \xi_i = s\biggl) \\, = \frac{s+1}{n+2}$$

В этой формулировке $\xi_1, \xi_2,..., \xi_{n+1}$ — это последовательность экспериментов, каждый из которых завершается успехом 
с вероятностью $p$ и неудачей с вероятностью $1-p$, т.е. случайная величина $\xi_i$ имеет распределение Бернулли с параметром $p$:
$$\xi_i \sim Bern(p) \\, \Leftrightarrow \\, \xi_i =
\left\\{
\begin{array}{l}
1, \\, p \\\\
0, \\, 1-p
\end{array}
\right.
$$

Вся суть правила последовательности заключается в том, что мы хотим оценить вероятность успеха следующего эксперимента при том, что мы мало знаем
о системе, которую исследуем. Всё, что нам известно, — это последовательность результатов независимых экспериментов, причём мы знаем, что 
каждый эксперимент может окончиться как успехом, так и неудачей. То есть вероятность $p$, с которой эксперимент оканчивается успехом, мы не
знаем, поэтому можно считать $p$ случайной величиной, принимающей значения на интервале $(0, 1)$. Важный момент здесь в том, что
$p$ — это, вообще говоря, не случайное значение, просто оно нам не известно, именно поэтому мы считаем его случайной величиной.

### Об априорном распределении случайной величины $p$

И тут мы встречаемся с ключевым вопросом: каково априорное распределение случайной величины $p$? Чтобы ответить на этот вопрос, 
необходимо понимать байесовскую интерпретацию вероятности. Она говорит о том, что вероятность — это степень уверенности в истинности суждения.
При получении новой информации о предмете суждения для определения степени уверенности используется <a class="text-link" href="https://ru.wikipedia.org/wiki/Теорема_Байеса" target="_blank">теорема Байеса</a>. По сути теорема Байеса
гласит, что априорную, т.е до получения любой дополнительной информации, вероятность нужно обновлять каждый раз, когда мы получаем новую 
информацию об объекте суждения, тем самым получая уже не априорную, а апостериорную вероятность, т.е. вероятность после получения новой 
информации.

Априорные вероятности могут быть как информативными, в том смысле, что они учитывают какие-то априорные знания о вероятностях событий, так
и неинформативными, т.е. учитывающими настолько мало, насколько это возможно.

Но как же измерить «информативность» априорного распределения вероятностей? На помощь приходит теория информации, которая изучает измерение
количества информации, свойства информации и т.д. На самом деле информацию можно воспринимать следующим образом: чем больше информации у вас есть
о каком-то событии, тем больше вы уверены в одном из возможных его исходов, и наоборот. То есть теория вероятностей и теория информации
довольно сильно связаны друг с другом.

Ключевым понятием в теории информации является 
<a class="text-link" href="https://ru.wikipedia.org/wiki/Информационная_энтропия" target="_blank">информационная энтропия</a>. 
Она характеризует меру неопределённости какой-либо системы. Для дискретной случайной величины $X$, принимающей $n$ независимых значений $x_i$, с распределением, заданным функцией вероятности $p_X(x_i) = P(X = x_i)$, информационная энтропия рассчитывается по формуле Шеннона, где 
$I(X) = -\log p_X(X)$ — <a class="text-link" href="https://ru.wikipedia.org/wiki/Собственная_информация" target="_blank">собственная информация</a>
случайной величины $X$: $$H(X) = -\sum_{i=1}^{n} p_X(x_i) \log p_X(x_i) = \mathbb{E}(I(X))$$

Чем больше энтропия распределения вероятностей, тем больше неопределённость, т.е. тем менее информативным является это распределение.
С помощью формулы Шеннона и метода множителей Лагранжа можно 
<a class="text-link" href="https://en.wikipedia.org/wiki/Lagrange_multiplier#Example_3:_Entropy" target="_blank">доказать</a>, что наименее информативным является равномерное распределение вероятностей. Интуитивно это можно понять на примере честной и нечестной монет: если вы подбрасываете честную монетку, у
которой вероятности выпадения орла и решки равны $1/2$, вы менее уверены в каком-либо из исходов, чем когда вы подбрасываете нечестную монетку, у которой
вероятности выпадения орла и решки, скажем, равны $2/3$ и $1/3$ соответственно. Честная монета как раз имеет равномерное распределение вероятностей.

Таким образом, так как в правиле последовательности мы ничего не знаем о вероятности $p$, с которой эксперимент оканчивается успехом, то можно сказать,
что случайная величина $p$ имеет непрерывное равномерное распределение на интервале $(0, 1)$, т.е. $p \sim U(0, 1)$. Такое непрерывное равномерное
распределение называют стандартным.

### Решение задачи

Пришло время доказать правило последовательности. Сначала я расскажу о «наивном», но красивом доказательстве, а потом представлю более строгое, комбинаторное доказательство, которое, отчасти, вывел сам.

Итак, как же можно объяснить правило последовательности? Так как мы изначально знаем, что эксперимент может окончиться как успехом, так и неудачей, можно предположить, что до всех экспериментов мы провели два эксперимента, один из которых был успешным, а другой — неудачным. Таким образом, мы провели в общей сложности не $n$ экспериментов c $s$ успехами, а $n+2$ эксперимента с $s+1$ успехами. То есть вероятность как раз получается $(s+1)/(n+2)$. Наверно, это самая интуитивно понятная интерпретация правила последовательности. На самом деле такой подход имеет отношение к так называемому <a class="text-link" href="https://en.wikipedia.org/wiki/Additive_smoothing" target="_blank">сглаживанию Лапласа</a> (англ. *additive smoothing, Laplace smoothing*), которое используется для сглаживания дискретных данных, т.е. нахождения аппроксимирующей функции, которая бы отражала важные паттерны в них. Однако, вообще говоря, такое решение всё равно требует математических обоснований. Тут же стоит заметить, что если бы нам изначально не было известно, что эксперимент может окончиться и успехом, и неудачей, то интересующая нас вероятность была бы равна $s/n$, т.е. просто частоте успеха. Однако можно строго доказать, что такая вероятность неверна тогда, когда $s = 0$ или
$s = n$. Интуитивно это можно понять так. Предположим, кто-то бросил монетку $5$ раз, и $5$ раз она выпала решкой. Эта монетка особенная, так как у неё может не быть орла на обратной стороне. Теперь вам разрешили самому бросить монетку. Какова вероятность, что опять выпадет решка? Вряд ли вы согласитесь, что она равна 
$$\frac{5}{5} \cdot 100\\% = 100\\%$$
В таком случае можно найти более правдивую оценку, однако это выходит за рамки этой статьи.
В общем, стоит запомнить, что правило последовательности отражает априорное предположение о том, что возможны как успех, так и неудача.

Теперь давайте рассмотрим комбинаторное доказательство на примере задачи о солнце. Представим вероятностную модель с помощью урновой схемы: пусть есть $N-1$ урна, в каждой по $N$ шаров, некоторые из которых белые, а некоторые — чёрные, причём в $k$-ой урне лежат $k$ белых шаров. Белый шар означает восход солнца, а чёрный — противоположную ситуацию:). Каждая урна — это модель, в соответствии с которой встаёт солнце с вероятностью $k/N$, если в урне $k$ белых шаров. Мы не знаем, какой модели соответствует наш мир, то есть не знаем, какая вероятность восхода солнца, поэтому, как и было описано ранее, будем считать вероятность восхода случайной величиной, принимающей значения из интервала $(0, 1)$, при этом она будет иметь априорное равномерное распределение, в нашем случае дискретное, так как количество урн конечно. Это будет означать, что вероятность каждой урны оказаться моделью для нашего мира равна $1/(N-1)$.

Допустим, на данный момент вы прожили $n$ дней от вашего рождения, из них ровно в $s$ днях взошло солнце. Конечно, если $s \neq n$, то вряд ли бы эта статья увидела свет, но всё же, так как мы доказываем общий случай правила последовательности, пусть солнце взошло именно $s$ раз, хоть и звучит это абсурдно. В контексте нашей схемы это можно изобразить так: мы тянем из какой-то урны $n$ шаров, из которых $s$ получаются белыми, причём после каждого вытягивания мы возвращаем шар обратно в ту же урну. Переложим теперь это на математический язык.

Как и было описано прежде, введём индикаторы $\xi_1, ..., \xi_{n+1}$, которые условно независимы относительно $p$ — вероятности восхода солнца, и $\xi_i \sim Bern(p)$. $i$-ый индикатор отвечает за $i$-тое вытягивание, причём если вытянутый шар оказывается белым, то $\xi_i = 1$, а иначе $\xi_i = 0$. Мы хотим узнать вероятность того, что в $(n+1)$-ый раз мы вытянем белый шар, то есть что солнце взойдёт в $(n+1)$-ый раз. По определению условной вероятности имеем:
$$P\biggl(\xi_{n+1} = 1\\, |\\, \sum_{i=1}^{n} \xi_i = s\biggl) \\, = \frac{P(\sum_{i=1}^{n+1} \xi_i = s+1)}{P(\sum_{i=1}^{n} \xi_i = s)} \quad (1)$$
Так как индикаторы условно независимы, то вероятность конкретной последовательности вытягиваний шаров из какой-то урны равна 
$$\left(\frac{k}{N}\right)^s \left(1 - \frac{k}{N}\right)^{n-s}$$
Здесь $k$ — количество белых шаров в этой урне, $n$ — количество вытягиваний, а $s$ — количество вытянутых белых шаров.
Тогда по формуле полной вероятности получаем для знаменателя:
$$P\biggl(\sum_{i=1}^{n} \xi_i = s\biggl) \\, = \frac{1}{N-1} \sum_{k=1}^{N-1} \left(\frac{k}{N}\right)^s \left(1 - \frac{k}{N}\right)^{n-s} \quad (2)$$
Непонятно, что теперь делать с этой суммой, однако, так как в свете введённого ранее обозначения $k/N = p$, то можно заметить, что при $N \rightarrow \infty$
$$\sum_{k=1}^{N-1} \left(\frac{k}{N}\right)^s \left(1 - \frac{k}{N}\right)^{n-s} \approx \int\limits_0^1 p^s (1-p)^{n-s}dp$$
Нам повезло, потому что такой интеграл уже изучен и называется бета-функцией, которая определяется так:
$$B(x, y) = \int\limits_0^1 t^{x-1} (1-t)^{y-1} dt$$
В нашем случае это $B(s+1, n-s+1)$. Известно следующее свойство бета-функции:
$$B(x, y) = \frac{\Gamma(x)\Gamma(y)}{\Gamma(x+y)},$$
где $\Gamma(x)$ — <a class="text-link" href="https://ru.wikipedia.org/wiki/Гамма-функция" target="_blank">гамма-функция</a>. Если $x \in \mathbb{N}$, то $\Gamma(x) = (x-1)!$, поэтому для $x, y \in \mathbb{N}$ имеем следующее: $$B(x, y) = \frac{(x-1)!(y-1)!}{(x+y-1)!}$$ Позже мы докажем это свойство, а пока давайте воспользуемся этим замечательным результатом. Получим, что 
$$B(s+1, n-s+1) = \int\limits_0^1 p^s (1-p)^{n-s}dp = \frac{s!(n-s)!}{(n+1)!}$$
Подставляя это в $(2)$, получаем следующее:
$$P\biggl(\sum_{i=1}^{n} \xi_i = s\biggl) \\, \approx \frac{1}{N-1} \int\limits_0^1 p^s (1-p)^{n-s}dp = \frac{s!(n-s)!}{(N-1)(n+1)!}$$
Аналогично действуем с числителем в $(1)$:
$$P\biggl(\sum_{i=1}^{n+1} \xi_i = s+1\biggl) \\, \approx \frac{1}{N-1} \int\limits_0^1 p^{s+1} (1-p)^{n-s}dp = \frac{(s+1)!(n-s)!}{(N-1)(n+2)!}$$
Тогда искомая вероятность равна
$$P\biggl(\xi_{n+1} = 1\\, |\\, \sum_{i=1}^{n} \xi_i = s\biggl) \\, \approx \frac{(s+1)!(n-s)!}{(N-1)(n+2)!} : \frac{s!(n-s)!}{(N-1)(n+1)!} = \frac{s+1}{n+2} \\; \blacksquare$$
Ура, мы доказали правило последовательности! На мой взгляд, это довольно красивое доказательство, так как оно не требует глубокого знания теории вероятностей. Если же вы хорошо знакомы с ней, то советую разобраться с <a class="text-link" href="https://en.wikipedia.org/wiki/Rule_of_succession#Mathematical_details" target="_blank">доказательством</a> на Википедии, а также <a class="text-link" href="https://jonathanweisberg.org/post/inductive-logic-2/" target="_blank">доказательством</a> Джона Вайзберга.

### Доказательство свойства бета-функции
Давайте теперь докажем использованное нами свойство бета-функции для случая натуральных $x$ и $y$. Представим, что $x$ — фиксированное натуральное число, и будем доказывать индукцией по $y$:

$(1)$ База индукции, $y = 1$: $$B(x, 1) = \int\limits_0^1 t^{x-1} dt = \frac{t^x}{x}|_0^1 = \frac{1}{x} = \frac{(x-1)!}{x!} = \frac{(x-1)!(y-1)!}{(x+y-1)!}$$

$(2)$ Пусть формула верна для $y = n$: $$B(x, n) = \int\limits_0^1 t^{x-1} (1-t)^{n-1} dt = \frac{(x-1)!(n-1)!}{(x+n-1)!}$$

$(3)$ Индукционный переход: докажем, что это верно для $y = n+1$. С помощью интегрирования по частям получаем, что
$$B(x, n+1) = \int\limits_0^1 t^{x-1} (1-t)^{n} dt = \frac{t^x(1-t)^n}{x}|_0^1 + \int\limits_0^1 \frac{t^xn(1-t)^{n-1}}{x} dt =$$
$$= \int\limits_0^1 \frac{t^xn(1-t)^{n-1}}{x} dt$$
Тогда, пользуясь предположением $(2)$, получаем, что $$\frac{n}{x} \int\limits_0^1 t^{(x+1)-1}(1-t)^{n-1} dt = 
\frac{nx!(n-1)!}{x(x+1+n-1)!} = \frac{(x-1)!((n+1)-1)!}{(x+(n+1)-1)!}\\; \blacksquare$$

### Выводы
Эта задача великолепна всем: и тем, что правило последовательности, использующееся для её решения, применимо ко многим жизненным ситуациям (формула до сих пор используется), и тем, что она поднимает серьёзные философские вопросы теории вероятностей, и просто своими красивыми решениями. Я надеюсь, что вам эта задача понравилась так же, как и мне, а статья натолкнула вас на интересные размышления и вдохновила на дальнейшее изучение математики.

### Источники
<ul class="sources">
  <li class="source"><a class="text-link" href="https://en.wikipedia.org/wiki/Sunrise_problem" target="_blank">Sunrise problem (Wikipedia)</a></li>
  <li class="source"><a class="text-link" href="https://en.wikipedia.org/wiki/Rule_of_succession" target="_blank">Rule of succession (Wikipedia)</a></li>
  <li class="source"><a class="text-link" href="https://jonathanweisberg.org/post/inductive-logic-2/" target="_blank">Laplace's Rule of Succession (Jonathan Weisberg's blog)</a></li>
  <li class="source"><a class="text-link" href="https://www.freecodecamp.org/news/will-the-sun-rise-tomorrow-255afc810682/" target="_blank">Will the sun rise tomorrow? (freeCodeCamp)</a></li>
</ul>